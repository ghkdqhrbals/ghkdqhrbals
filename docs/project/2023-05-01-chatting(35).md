---
layout: default
title: 35. Spring Cloud 기반 MSA 변환 시작-9(성능이슈 해결 과정)
parent: 📌 실시간 채팅서버 프로젝트
nav_order: 35
---

MSA 버전과 이전 모노 버전에서의 **변경된 점**과 **성능 문제점** 및 **해결 과정**을 설명하려 합니다.

일단 먼저 변경점을 아래와 같이 정리해보았어요.

# 1. 변경된 점

| 변경점                                 | 기존                                                             | 변경                                                                                                                                                                                                                 |
|-------------------------------------|----------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Tomcat -> Netty -> Undertow**     | Tomcat 을 사용하면서 max connection = 10000 을 통해 동시성 증대 및 timeout 설정 | [Netty 장점 포스팅](https://ghkdqhrbals.github.io/portfolios/docs/Java/6/) Non-blocking 에 최적화됨. 하지만 Netty 의 설정들을 Spring boot 에서 변경하기가 까다로움. yaml 파일로 configuration 할 수 있는 메소드들이 별로 없기때문. 그래서 Netty based Undertow 를 사용. |
| **서비스 별 RDB 분할**                    | RDS 1대를 유저 서비스/채팅 서비스/고객 서비스가 사용함                              | AWS RDS 1대를 유저 서비스가 사용하고, 채팅과 고객서비스는 각각 local RDB 를 사용함                                                                                                                                                            |
| **이벤트 트랜젝션 캐싱 관리**                  | 이벤트 트랜젝션 개념이 없었음                                               | 이벤트를 하나의 트랜젝션으로 일관되도록 관리하는 테이블을 추가함. update:O, event-sourcing:X. Saga의 Orchestration 패턴! 해당 부분을 RDB로 처리하기엔 상당한 리소스가 소모됨. 따라서 Redis 로 관리.                                                                           |
| **메세지 큐 상세 설정**                     | MQ 사용을 했지만, 응답과 롤백을 받지 않았음                                     | Kafka 설정 및 [유저 관리 요청, 유저 관리 응답, 채팅유저 보상 이벤트, 고객유저 보상 이벤트] 총 4가지 토픽과 파티션 추가                                                                                                                                         |
| **Spring-cloud configuration 추가**   | 각각의 configuration 파일을 따로 관리하였음                                 | config-server 와 rabbitmq 를 통해 git에서 설정 파일을 클론하고 이를 모든 서버가 사용할 수 있도록 함. 또한 모두 모듈화하여 통합 gradle 관리 설정                                                                                                                 |
| **Spring-cloud eureka, gateway 추가** | nginx 로 모든 서비스들의 endpoint 를 **직접** 엮어주었음                       | eureka 서버에 등록하고 gateway 는 이를 자체적으로 load-balancing 하도록 설정하였음                                                                                                                                                        |
| **Spring-security, JWT 인증/인가 추가**   | 인증과 인가를 세션으로 관리함                                               | 세션 관리 + JWT 토큰의 payload 에 저장된 permission 정보, 유저ID 를 통해 인증과 인가를 구현함. 특히 Reactor 설정을 따로 하였음                                                                                                                          |


# 2. 성능비교 및 문제점

![img](../../../assets/img/msa/113.svg)

생각보다 상당히 낮은 성능 수치를 보여줍니다. 현재 생각하는 문제점은 유저 서비스에서 Kafka까지 메세지가 전송되는 비율이 상당히 낮다는 점입니다. 아래의 그림을 보면 이해가 될거에요(아래의 그림은 **동시에 100개의 API 요청을 보냈을 때 Kafka 토픽 내 새로운 record 개수**입니다).

![img](../../../assets/img/msa/115.png)
![img](../../../assets/img/msa/116.png)

보시다시피 유저 서비스에서 Kafka 에 메세지를 전송하는 rate가 초당 **평균적으로 10개** 인것을 확인할 수 있습니다. 고객 서비스나 채팅 서비스에서 이를 소비하는 부분에서는 문제가 없죠. 애초에 적은 수의 이벤트를 수신받았으니까요!

그래서 이 부분을 아래의 몇가지 체크리스트를 가지고 개선하려고 합니다(적다보니 많네요ㅎㅎ...).

1. Undertow 의 적은 parellel thread
2. Spring Security 의 토큰 확인 절차에서 발생할 수 있는 딜레이 문제
3. 이벤트 트랜젝션을 관리하는 Redis 저장 성능 문제
4. 적은 Kafka Producer 스레드 개수
5. linger.ms 와 batch_size 문제
6. 잦은 스레드 변경으로 인한 높은 Context Switch 비용
7. CPU/Memory 부족


# 3. 성능 이슈 해결
## 3.1 (Step1)과정

| 문제점 | 설명                                                                                                                                                                                                                                                                                                                                                                    |  문제였나?   |
|------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------:|
|Undertow 의 적은 parellel thread|| ⏳                                                                                                                                                                                                                                                                                                                                                                     |
|Spring Security 의 토큰 확인 절차에서 발생할 수 있는 딜레이 문제|| ⏳                                                                                                                                                                                                                                                                                                                                                                     |
|이벤트 트랜젝션을 관리하는 Redis 저장 성능 문제| 실측 결과, 인상적이였습니다. 동시에 100개의 요청 시, 258ms 소요. 동시에                                                                                                                                                                                                                                                                                                                        |    ❌     |
|적은 Kafka Producer 스레드 개수| Producer 스레드를 늘려도 똑같을 거에요. 이유는 다음과 같습니다. 이벤트를 전송함에 있어 필요한 것은 1. 충분한 CPU 리소스, 2. 충분한 네트워크 입니다. 충분한 네트워크는 아래의 `linger.ms 와 batch_size 문제`에서 설명드리겠습니다. 나머지 충분한 CPU 리소스는 문제가 되지 않다고 보여집니다. 왜냐하면, 기존에 Mono 서버에서도 싱글 Producer 스레드를 사용하였을 때 높은 성능이 나왔기 때문이죠. 즉, 스레드를 느린다고 하더라도 성능이 증가하지 않을거에요. 실측 결과, 전송 속도는 동시에 100개의 요청을 받았을 때, 493ms 가 걸립니다.                              | ❌|
|linger.ms 와 batch_size 문제| linger.ms 는 이벤트 전송 대기 시간, batch_size는 이벤트를 묶어서 보내는 크기 입니다.기존에는 이벤트 전송 전까지 50ms 기다리고 최대한 50개를 묶어서 보내도록 설정했어요. 하지만, 보다시피 평균적으로 10개만 보내는 것을 이미 우리가 확인했죠. 즉, **이벤트를 전송하는 것에 대한 네트워크 로드는 낮다, 때문에 문제가 되지 않는다**. 라도 판단됩니다.                                                                                                                                                   |❌|
|잦은 스레드 변경으로 인한 높은 Context Switch 비용|| ⏳                                                                                                                                                                                                                                                                                                                                                                     |
|CPU/Memory 부족| 18개 컨테이너의 CPU 점유 목록 ![img](../../../assets/img/msa/117.png) ![img](../../../assets/img/msa/118.png) 도커가 많은 CPU 를 소모하고 있습니다. 그 중 특히 **유저 서비스 컨테이너**에 CPU usage : **821%** 로 많은 과부하가 걸리고 있는 것을 확인할 수 있어요. 이는 직접적인 개선점이 아닌 간접적인 개선점이겠죠? 또한, **실제 테스트가 끝난 이후에도 계속 CPU를 잡아먹고 있습니다**... 왜 이런걸까요ㅜㅜ. 뭔가 큰일이 났습니다. Kafka 메세지에서 발생한 오류처리를 계속 수행하기 때문일까요? offset으로 보면 문제가 없는데 말이죠. | ✅                                                                                                                                                                                                                                                                                       |


## 3.2 (Step2)과정



1. Undertow 의 적은 parellel thread
2. Spring Security 의 토큰 확인 절차에서 발생할 수 있는 딜레이 문제
3. 이벤트 트랜젝션을 관리하는 Redis 저장 성능 문제
4. 적은 Kafka Producer 스레드 개수
5. linger.ms 와 batch_size 문제
6. 잦은 스레드 변경으로 인한 높은 Context Switch 비용
7. CPU/Memory 부족
8. SSE 이벤트 처리를 위한 Flux 스레드의 지속적인 사용
9. Kafka 이벤트 전송/수신 시, 스레드 데드락
10. (metadata.max.age.ms) 카프카 초기 토픽으로부터 메타데이터를 수집하기 위한 딜레이 타임아웃 미설정 default:5min
11. 

linger.ms = 50ms
kafka batch = 10
service max thread = 10 
Redis Save Time : 146, time:24, counts:100,
Kafka Sender Time : 363, time:418, counts:100

**시간이 지속될 수록 Kafka Sender Time 이 증가하는 현상을 발견!**
Kafka 전송 트래픽이 쌓이는 것.

* Producer 에서 재전송 하는 부분에서 트래픽이 발생한 것으로 보임!
> 멱등성 off 로 제거.
* 

request.timeout.ms = 30000
**retries = 2147483647**