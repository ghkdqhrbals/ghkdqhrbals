---
layout: default
title: 24. (작성중) Does HikariCP.getConnection() return the same Connection when run getConnection in different thread?
parent: 실시간 채팅서버 프로젝트
nav_order: 24
---

{: .important }
> HikariCP를 사용하던 중, 새로운 스레드에서 `hikariDataSource.getConnection()` 을 수행했지만 다른 스레드에서 사용하던 Connection 이 반환되었습니다. 3일간 해결이 안되서 stack-overflow 에 질문을 올렸습니다ㅜㅜ. 혹시 왜 이런 현상이 발생하는지 아신다면 아래의 링크에 답변을 남겨주시면 정말정말 감사하겠습니다!  
>
> Stack-overflow : [https://stackoverflow.com/questions/75781250/does-hikaricp-getconnection-return-the-same-connection-when-run-getconnection](https://stackoverflow.com/questions/75781250/does-hikaricp-getconnection-return-the-same-connection-when-run-getconnection)

# 아래는 작성중입니다 :) 잘못 해석한 내용이 엄청 많아요


@Transactional 과 HikariCP

Spring uses **AOP** to start and stop transactions.

# How to Use Spring Transactions With Multiple Threads

먼저 알아두어야 할 것은 JDBC connection 뿐만 아니라 그냥 모든 DB connection은 Thread bounded 라는 것입니다. 스레드에서 connection 을 **지역 변수로 선언**해서 사용해야만 한다는 것이죠. 좀 더 자세히 말하면 하나의 connection 은 여러 스레드에서 사용이 불가능하다는 것입니다. 사실 그럴 필요가 없는게, 만약 여러 스레드에서 하나의 connection을 두고 사용하게 된다면, 

애초에 이를 지원해주지 않지만

Resource management code should check for **thread-bound resources**, e.g. **JDBC Connections** or Hibernate Sessions,


As mentioned above,  actualTransactionActive thread local is used to check whether the transaction is active on the current thread.

This thread local is set true on the thread which initializes the transaction. But, since this thread local value is not visible to other threads, we have to maintain another boolean flag to inform the activeness of the transaction to other threads. Then we can check that flag from the new thread and set actualTransactionActive thread local to true manually. Thread local value can be set by calling following code line:


The database transaction scope start element[1] starts the transaction scope. 
All the database operations happening within transaction scope are guaranteed to be committed if and only if all the operations within the transaction scope were a success. 
Then the clone message processing element[2] just takes a clone of the message and sends one copy as the response to the nio http ingress connector and the other copy to the database processor. 

**Two new threads are created here and thread locals of the TransactionSynchronizationManager class are copied to the newly created threads**. 
새로운 스레드가 생성되면, 트랜젝션 동기화 매니저가 새로운 스레드에 카피됩니다. 즉, 기존에 트랜젝션 동기화 매니저가 저장하고 있는 Connection 을 가져올 수 있는 것이죠.

Then, database processing element[3] does the first insert to the people table in the database.
Next, database processing element[5] reads the last inserted row from the people table and returns the result in DBResultsSetFormat.
Then we use a custom processing element[6] to extract the id from the DBResultsSetFormat and set it to the header of the message. The last database processing element, element[7], does the second insert to the students table using the data read from the payload the id read from the message header. Finally, the database transaction scope end element closes the transaction scope and commit the changes to the database if all the operations are complete. The database transaction will be rolled back in any kind of failure within the transaction scope of the flow.

* Database Processing Element : The database connector and the database processing element provide the data persistent capabilities to Project-x. There are three main components to perform database operations: **db egress connector**, **db ingress connector**, and the **db processing element**. Database processing element supports for all four CRUD operations. Database egress connector provides create, update, delete operations and database ingress connector provides read operation in a timed manner.

[https://dzone.com/articles/spring-transaction-management-over-multiple-thread-1](https://dzone.com/articles/spring-transaction-management-over-multiple-thread-1)

즉, 새로운 @Transactional 어노테이션은 AOP를 통해 

* Spring은 AOP 로 @Transactional 관리

# 장애 확인
저는 Hikari를 사용하여 Connection Pool을 관리합니다. HikariCP의 최대 CP 개수를 최적화 하기 위해 고민하던 와중, 하나의 Task 에 HikariCP 에서 두 개의 connection 이 사용되고 있었습니다! 왜 이런걸까요?ㅜㅜ... 지금부터 장애를 확인하기 전에 단일 쿼리 실행 과정부터 확인해볼게요.
 



@Transactional 어노테이션이 붙은 메소드를 실행하게 된다면, HikariCP 에서 Tracing 하기 위한 Conenction 을 하나 더 붙입니다. 얘는 톰켓 스레드에 붙어서 클라이언트로부터 ProxyConnection.close 를 받으면(연결이 종료되면) conenction 을 HikariCP에 돌려주는 형식이죠.

# 단일 쿼리 실행 과정

먼저 단일 쿼리를 실행하는 과정을 한번 볼까요? 간단히 나타내면 아래와 같은 순서로 나타내지겠죠?

1. `hikariDataSource.getConnection()`를 통해 Connection 을 HikariCP 에서 가져옵니다. 
2. `connection.prepareStatement(sql)`으로 해당 connection 으로 쿼리합니다.
3. 이후 connection, preparedStatement, resultSet 를 반환합니다. 

```java
   try {
     connection = hikariDataSource.getConnection(); 
     preparedStatement = connection.prepareStatement(sql);
     resultSet = preparedStatement.executeQuery();
   } catch(Throwable e) {
     throw new RuntimeException(e);
   } finally {
     if(preparedStatement != null) {
       preparedStatement.close();
     }
     if(connection != null) {
       connection.close(); // 여기서 HikariCP 에 커넥션을 반환합니다.
     }
     if(resultSet != null){
        resultSet.close();
     }
   }
```

자 그렇다면, **하나의 쿼리가 실행되기 위해서 HikariCP는 몇 개의 Connection 을 할당할까요?**

아래의 장애대응 문서를 확인했지만, 저와는 조금 다른 케이스인것 같아서 
[https://jaehun2841.github.io/2020/01/27/2020-01-27-hikaricp-maximum-pool-size-tuning/#하나의-Query가-실행되는-과정](https://jaehun2841.github.io/2020/01/27/2020-01-27-hikaricp-maximum-pool-size-tuning/#하나의-Query가-실행되는-과정)

# 

# HikariCP Dead Lock 방지




HikariCP는 클라이언트와 연결되었기때문에, 내부에서 conenction을 종료시키더라도 


```
[nio-8080-exec-2] chatting.chat.web.UserController         : HikariCP[Total:10, Active:0, Idle:10, Wait:0]-nio 스레드
[nio-8080-exec-2] c.c.domain.user.service.UserServiceImpl  : HikariCP[Total:10, Active:0, Idle:10, Wait:0]-Repository 접근 전
[nio-8080-exec-2] c.c.web.logger.DataSourceAspectLogger    : Before findUser: [Total: 10, Active: 1, Idle: 9, Wait: 0]
[nio-8080-exec-2] c.c.d.u.repository.UserRepositoryJDBC    : HikariCP[Total:10, Active:1, Idle:9, Wait:0]@Transactional Repository 메소드 시작
[    db-thread-1] c.c.d.u.repository.UserRepositoryJDBC    : HikariCP[Total:10, Active:1, Idle:9, Wait:0]connection 가져오기 전
[nio-8080-exec-2] c.c.web.logger.DataSourceAspectLogger    : After findUser: [Total: 10, Active: 1, Idle: 9, Wait: 0]
[    db-thread-1] c.c.d.u.repository.UserRepositoryJDBC    : HikariCP[Total:10, Active:2, Idle:8, Wait:0]connection 가져온 후
[    db-thread-1] c.c.d.u.repository.UserRepositoryJDBC    : HikariCP[Total:10, Active:1, Idle:9, Wait:0]connection 반환 후
[service-thread-1] c.c.domain.user.service.UserServiceImpl  : Hikari CP 정보 : Total:10, Active:1, Idle:9, Wait:0 (서비스)
```











#### INDEX
0. 성능개선결과부터!
1. 어떻게? 어디에서 성능개선을 하였을까요?

# 0. 성능개선결과부터! (feat. [gotybench](https://github.com/ghkdqhrbals/gotybench))

![img](../../../assets/img/performance/1.png)

중간중간에 DB connection이 반환되지 않아서 대기하던 곳 또한 전체적으로 완화되었습니다!

이에 따라서 평균/최대/최소 응답시간이 아래와 같이 전체적으로 개선되었어요.

* 평균 응답시간 개선 : 1.1초 -> **0.9초**
* 최대 응답시간 개선 : 5.4초 -> **3.9초**
* 최소 응답시간 개선 : 0.027초 -> **0.02초**


원하는 전체 과정은 아래와 같습니다.
1. 서비스 스레드 풀에서 스레드를 가져와서 서비스가 실행됩니다.
2. 서비스는 리포지토리를 **blocking**으로 호출합니다.
3. 리포지토리는 hikari connection 풀에서 connection 을 가져와 사용합니다. 이 때, 별도로 할당한 스레드 풀에서 스레드 하나를 가져와서 쿼리합니다.
4. 쿼리 트랜젝션이 끝나면, Spring의 `JdbcTemplate` 은 해당 DB connection 을 다시 connection 풀에 release합니다.
   > 또한 PrepareStatement 를 자동으로 close 합니다. 기존 우리가 connection 받아오고, try/catch 에다가 pstmt.close()하고, connection.close() 했었잖아요? 이러한 반복되는 과정을 JdbcTemplate 는 자동으로 실행되도록 해줍니다! 그래서 JdbcTemplate을 사용했어요. 그리고 Spring 어느 버전 이후로 기본적으로 JDBC는 고성능 HikariCP를 사용하기 떄문에 application.properties 에 몇가지 추가해주면, 쉽게 CP를 설정할 수 있어요.
5. 서비스는 blocking 된 결과를 가져와서 만약 쿼리가 정상 동작했다면 Kafka에 메세지를 보내 Chat 서버가 다음기능을 수행하도록 합니다. **이 때, `thenAcceptAsync` 를 통해 DB 쿼리 스레드가 계속해서 이후 과정을 수행하지 않도록 설정합니다.**

# 1. 어떻게? 어디에서 성능개선을 하였을까요?
저는 다음과 같이 서비스와 데이터베이스에 별도의 스레드 풀을 할당해서 사용하는데요.

해당 과정에서 데이터베이스 쿼리 스레드가 나머지 서비스를 계속 타게 되었습니다.

**당연히 데이터베이스의 connection 을 물고있는 쿼리 스레드가 나머지 서비스를 실행하지 않고 빠르게 반환되어야겠죠?**



그래서 아래와 같이 서비스에서 리포지토리를 호출 한 뒤, thenAcceptAsync를 통해 리포지토리의 스레드를 반환하도록 설정하였습니다.

```java
@Slf4j
@Repository
public class UserRepositoryJDBC {
   public CompletableFuture<?> saveAll(List<User> users) {
      return CompletableFuture.runAsync(() -> {
         String sql = "INSERT INTO user_table (user_id, email, join_date, login_date, logout_date, user_name, user_pw) " +
                 "VALUES (?, ?, ?, ?, ?, ?, ?) ";
         jdbcTemplate.batchUpdate(sql,
                 users,
                 batchSize,
                 (PreparedStatement ps, User user) -> {
                    ps.setString(1, user.getUserId());
                    ps.setString(2, user.getEmail());
                    ps.setObject(3, user.getJoinDate());
                    ps.setObject(4, user.getLoginDate());
                    ps.setObject(5, user.getLogoutDate());
                    ps.setString(6, user.getUserName());
                    ps.setString(7, user.getUserPw());
                 });
      }, databaseExecutor).exceptionally(e -> {
         log.info(e.getMessage());
         if (e.getCause().getClass() == DuplicateKeyException.class) {
            throw new CustomException(DUPLICATE_RESOURCE);
         }
         throw new RuntimeException();
      });
   }
}

@Slf4j
@Service
@Transactional
public class UserServiceImpl extends KafkaTopicConst implements UserService {
   ...
   @Override
   public CompletableFuture<?> save(User user) throws CustomException {
      DeferredResult<ResponseEntity<?>> dr = new DeferredResult<>();
      return CompletableFuture.supplyAsync(()->{
         return Arrays.asList(user);
      }, serviceExecutor).thenAccept(u -> {
         try {
            userRepositoryJDBC.saveAll(u).get(); // 당연히 쿼리 스레드는 Blocking!
         } catch (InterruptedException e) {
            throw new RuntimeException(e);
         } catch (ExecutionException e) {
            throw new RuntimeException(e);
         }
      }).exceptionally(e -> {
         log.info("서비스 에러");
         if (e.getCause() instanceof CustomException){
            CustomException ex = (CustomException) e.getCause(); // 에러 unwrapping
            throw ex;
         } else{
            throw new RuntimeException(); // default 에러 송출
         }
      });
   }
   ...
}

@Slf4j
@RestController
@RequestMapping("/auth")
@RequiredArgsConstructor
public class UserController extends KafkaTopicConst {
   ...
   @PostMapping("/user")
   public DeferredResult<ResponseEntity<?>> addUser(@RequestBody RequestAddUserDTO request) throws InterruptedException {
      DeferredResult<ResponseEntity<?>> dr = new DeferredResult<>();

      User user = new User(
              request.getUserId(),
              request.getUserPw(),
              request.getEmail(),
              request.getUserName(),
              LocalDate.now(),
              LocalDate.now(),
              LocalDate.now()
      );

      // 유저 서비스를 통해 유저 저장
      saveUserHandler(dr, user);
      return dr;
   }

   private void saveUserHandler(DeferredResult<ResponseEntity<?>> dr, User user) {
      CompletableFuture
              .runAsync(() -> {
              }).thenCompose(s -> {
                 return userService.save(user);
              }).thenAcceptAsync(s1 -> { // 이 부분에서 thenAccept -> thenAcceptAsync을 통해 데이터베이스에 할당한 스레드 풀을 반환시킵니다.
                 sendToKafkaWithKey(TOPIC_USER_CHANGE, new RequestUserChange(user.getUserId(), user.getUserName(), "", "INSERT"), user.getUserId());
                 dr.setResult(ResponseEntity.ok("success"));
              }).exceptionally(e -> {
                 if (e.getCause() instanceof CustomException) {
                    dr.setResult(ErrorResponse.toResponseEntity(((CustomException) e.getCause()).getErrorCode())); // 에러 클라이언트에게 전달
                 } else {
                    dr.setResult(ResponseEntity.badRequest().body("default bad request response")); // default 에러
                 }
                 return null;
              });
   }
   ...
}
```


## JdbcTemplate 사용전

```java
   PreparedStatementCreator creator = new PreparedStatementCreator() {
       @Override
       public PreparedStatement createPreparedStatement(Connection con) throws SQLException {
           PreparedStatement updateSales = con.prepareStatement(
                   "SELECT * FROM user_table WHERE user_id = ? OFFSET 0 LIMIT 1");
           updateSales.setString(1, user_id);
           System.out.println(updateSales.toString());
           return updateSales;
       }
   };
   PreparedStatement pstmt = null;
   Connection conn = null;

   try {
       conn = jdbcTemplate.getDataSource().getConnection();
       pstmt = creator.createPreparedStatement(conn);
       pstmt.execute();
       ...
       Thread.currentThread().sleep(20000);
   } catch (SQLException e) {
       throw new RuntimeException(e);
   } catch (InterruptedException e) {
       throw new RuntimeException(e);
   } finally {
       try {
           /* 자원해제 */
           if(pstmt != null) {
               pstmt.close();
           }
           if(conn != null) {
               conn.close();
           }
       } catch (SQLException e) {
           e.printStackTrace();
       }
   }
```

## JdbcTemplate 사용후

```java
 List<User> query = jdbcTemplate.query(
           "SELECT * FROM user_table WHERE user_id = ? OFFSET 0 LIMIT 1",
           new RowMapper<User>() {
               @Override
               public User mapRow(ResultSet rs, int rowNum) throws SQLException {
                   User us = new User(
                           rs.getString("user_id"),
                           rs.getString("user_pw"),
                           rs.getString("email"),
                           rs.getString("user_name"),
                           rs.getTimestamp("join_date").toLocalDateTime().toLocalDate(),
                           rs.getTimestamp("login_date").toLocalDateTime().toLocalDate(),
                           rs.getTimestamp("logout_date").toLocalDateTime().toLocalDate());
                   return us;
               }
           }, user_id);
   
   if (query.size() < 1){
       throw new CustomException(CANNOT_FIND_USER);
   }
   
   try {
       Thread.currentThread().sleep(20000);
   } catch (InterruptedException e) {
       throw new RuntimeException(e);
   }
   return query.get(0);
```